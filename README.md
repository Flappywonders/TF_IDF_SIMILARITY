# TF_IDF_SIMILARITY
text similarities between each text using TF-IDF

### Environment 
python 3.7

### Architecture(main.py)
1. 读取源文件，进行简易的数据清洗和格式整理（预处理）：使用gbk编码打开文件，逐行读取数据，使用正则表达式进行数据清洗，将结果使用字典存储；
2. 遍历每一个在文档中的语句，根据公式分别计算其TF;
3. 根据公式计算TF-IDF：首先对清洗后的源数据进行遍历，获得一个完整的词表，统计单词在整个文档里出现在多少文本中，并根据公式计算IDF；
4. 计算每句话对应的TF-IDF向量；
5. 由于在TF的计算过程中，只存储了每句话中的词的TF值，而没有存储在词表中而在该句话中未出现的词的TF（其值为 0），可能导致两句话的TF-IDF向量的元素个数不相等。（标准情况下需要存储不存在的词的TF为0，并严格按照词表位置存储），故在向量点乘时，需要对每句话中对应相等的单词进行定位，并由相应位置的TF-IDF值相乘，获得中间结果。在获得点乘结果后，进行结果判断：如果其值为0，则表明这两句话完全不相关，输出值为0.0。如果不为0，则根据余弦计算公式计算向量的长度，并计算最终的相似度结果。
6. 结果存储

### Optimization
1. 其次进行浮点数运算优化，由于程序中绝大部分计算为浮点数计算，尤其是计算余弦时存在着密集的浮点运算，所以浮点运算速度的提高能够极大优化程序的运行效率，这里将余弦计算模块使用cython 编译；
	（1）创建文件cul_cos.pyx，将计算函数拷贝；
  （2）创建setup.py文件进行配置，编译文件，生成cul_cos.c 和cul_cos.cpython-37m-darwin.so文件供调用；
  （3）在主程序中调用生成的函数，运行
  
2. 进行结果存储的优化，采用pickle模块进行大量数据存储，通过调用pickle.dump()将文件传入result.pickle；
3. 进行并行计算优化，通过调用python的multiprocessing实现：
  （1）首先判断自己计算机的cpu支持的最大进程数n（本程序使用的是4）
  （2）将要处理的循环平均分成n部分
  （3）多线程对分割好的TFIDF字典分别计算，生成四个顺序结果result0,result1,result2,result3，分别对应(0, 2500)->all,(2500, 6000)->all,(6000,10000)->all,(10000,end)->all四个部分的计算结果，并进行结果的拼接；

